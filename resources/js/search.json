[[{"l":"Welcome to the Baselime Documentation","p":["Baselime is an observability as code platform for serverless architectures. It helps developers collect, analyze, and understand the telemetry data generated by their serverless applications. With Baselime, you can:","Ingest logs, metrics, traces, and other telemetry data from your serverless applications","Use multiple interfaces to interact with your data, including a web console, a CLI, and a Visual Studio Code extension","Integrate with tools you already use, such as GitHub, Slack, Jenkins, and PagerDuty"]},{"i":"what-is-observability-as-code","l":"What is Observability as Code?","p":["Observability as code is the practice of treating the monitoring and debugging of an application as part of the application's codebase. This means that the configuration of monitoring and debugging tools is stored in version control and treated like any other code.","With observability as code, you can:","Maintain a clear, up-to-date record of how your application is being monitored and debugged","Collaborate with your team on monitoring and debugging configuration","Automate the provisioning and configuration of monitoring and debugging tools","Baselime is built on the OpenTelemetry observability framework, which provides a standard way to instrument applications for observability. With Baselime, you can easily implement observability as code in your serverless applications."]},{"i":"what-is-telemetry-data","l":"What is Telemetry Data?","p":["Telemetry data is information about the performance and behavior of an application. It includes:","Logs: Recorded messages that provide information about the application's execution","Metrics: Quantitative measurements of the application's performance, such as CPU usage or request latency","Traces: Detailed records of the steps taken by the application as it processes a request","Collecting and analyzing telemetry data is essential for understanding the health and performance of an application. With Baselime, you can easily ingest and analyze telemetry data from your serverless applications."]},{"l":"Guides","p":["Quickstart: Get up and running with Baselime in a few simple steps","Ingesting Data: Learn how to ingest telemetry data from your serverless applications","Analyzing Data: Discover how to use the various interfaces provided by Baselime to analyze and understand your data","Integrations: Find out how to connect Baselime with your favorite tools"]},{"l":"Reference","p":["Reference Guide: Learn about the Baselime Observability Reference Language (ORL) and how to use it to define observability configurations","API Reference: Detailed documentation of the Baselime API","CLI Reference: Complete reference for the Baselime command-line interface"]},{"l":"Community","p":["Join the Baselime community to get help with using the platform, share your own experiences, and stay up-to-date with the latest developments.","Slack: Join our Slack community to connect with other Baselime users and get real-time support from the Baselime team","Blog: Read about the latest features, best practices, and more from the Baselime team","Social media: Follow us on Twitter, LinkedIn, and YouTube to stay up-to-date with the latest news and updates from Baselime","We look forward to connecting with you!"]}],[{"l":"Quickstart Guide","p":["Welcome to Baselime! This quickstart guide will help you get up and running with the platform in just a few simple steps.","All you need is:","An AWS Account","Permissions to deploy a CloudFormation stack with IAM role.","A deployed application leveraging AWS Lambda and other AWS serverless services","If you do not have a deployed application, you can use one of our example applications."]},{"i":"step-1-sign-up-for-baselime","l":"Step 1: Sign up for Baselime","p":["To use Baselime, you'll need to sign up for an account. You can sign up for a free account here.","Create a workspace. Typically this will be the name of your organisation.","Start exploring the telemetry data in your workspace sandbox."]},{"i":"step-2-optional-install-the-baselime-cli","l":"Step 2: (Optional) Install the Baselime CLI","p":["The Baselime CLI is a command-line tool that you can use to interact with the platform. Installing the CLI can make it easier to work with Baselime, unlocks Observability as Code and provides additional functionality not available in the web console. To install the CLI, follow the instructions here."]},{"i":"step-3-connect-your-aws-account","l":"Step 3: Connect your AWS account","p":["To start collecting telemetry data from your serverless application, you'll need to connect your AWS account to Baselime. This is done by deploying a CloudFormation template onto your AWS account.","To generate and download the CloudFormation template:","Go to the Baselime Console or run the following command in the Baselime CLI:","Follow the prompts to generate and download the template.","Next, you must deploy the template to your AWS account:","Click the link provided by the Baselime Console or CLI to open the CloudFormation service in your AWS account","Check the box to acknowledge that the template creates IAM roles","Click \"Create stack\" to deploy the stack, making sure to use the correct credentials and region for your AWS account","We've open-sourced the CloudFormation template here.","Once the stack is deployed, telemetry data from your AWS account will be automatically ingested by Baselime and will be available through the various clients.","To verify the connection, invoke any deployed AWS Lambda function in your account and you should see data from it in the Baselime console within seconds. Additionally, you can stream all the events ingested by Baselime directly in your terminal using the baselime tail command.","If you do not complete any of the above steps, Baselime will not be able to ingest data from your AWS account.","If you do not see any data in the Baselime UI or using the baselime tail command within seconds of completing the above steps, something went wrong. Please contact us."]},{"i":"step-4-explore-the-data","l":"Step 4: Explore the data","p":["Once your AWS Account is connected, you can start exploring the telemetry data it generates. You can use the web console or the CLI (if installed) to access and analyze the data.","Baselime ingests and indexes every field and nested field in your telemetry data."]},{"l":"Accessing data in the web console","p":["To explore the data in the web console:","Go to the Baselime Console and sign in with your account","Select your environment from the list of environments","Use the various filters and tools in the console to slice and dice the data, such as:","Filtering by resource type, key-value pair, operation type, or time range","Searching for specific strings or regexes in the data","Viewing the trace data for a specific request or operation","Viewing the logs and metrics for a specific resource or operation","Segmenting the results by specific field or nested field"]},{"l":"Accessing data in the CLI","p":["To access the data in the CLI:","If you installed the CLI, you can use the baselime query command to interactively explore the data. Here's how it works:","If you haven't already done so, sign in to the CLI using the baselime login command","Run the following command:","Select the service you want to query","Select one of your saved queries or interactively build a query","Enter the start and end time for the query (optional - defaults to the past hour)","The command will output a table with the results of the query and a unique URL that you can share with your team"]},{"i":"step-5-implement-observability-as-code","l":"Step 5: Implement Observability as Code","p":["Baselime enables you to define and manage your observability configurations, such as queries and alert rules, using code that can be stored and versioned in your source control repository. This is known as Observability as Code.","To implement observability as code:","Use the baselime init command to create a .baselime folder in your repository and generate an index.yaml file","Answer the prompts to specify metadata about your service, such as its name, description, and details about the cloud infrastructure of the service","The baselime init command will create one or more configuration files in the .baselime folder using the Baselime Observability Reference Language (ORL). The ORL provides a set of commands and syntax for defining configurations such as queries, alert rules, and dashboards.","Use the baselime push command to apply your configurations to your environment.","For example:","This will apply your observability configurations to your environment, replacing any existing configurations.","To verify that your configurations have been applied, use the baselime plan command to compare your local configuration files with the ones deployed in your environment.","For more information about the Baselime ORL and how to use it, check out the Reference Guide."]},{"i":"step-6-set-up-integrations","l":"Step 6: Set up integrations","p":["Baselime offers a variety of integrations with popular tools and services to help you get the most out of your observability data.","To set up an integration:","Go to the Integrations page in the Baselime console","Choose the integration you want to set up from the list","Follow the prompts to configure the integration. This may include providing credentials or setting up webhooks.","Save your changes to complete the setup","For more information about the available integrations and how to use them, check out the Integrations Guide."]},{"i":"step-7-learn-more","l":"Step 7: Learn more","p":["Congratulations on completing the Baselime Quickstart guide! You should now be up and running with Baselime, collecting telemetry data from your serverless applications and implementing observability as code.","To learn more about what you can do with Baselime, check out the following resources:","Reference Guide: Learn about the Baselime Observability Reference Language (ORL) and how to use it to define observability configurations","Integrations Guide: Learn about the available integrations and how to use them to get the most out of your observability data","Tutorials: Follow step-by-step guides to learn how to use Baselime in different scenarios","Slack Community: Join the Baselime community on Slack to ask questions, share tips and tricks, and get help from other users","We hope you enjoy using Baselime! If you have any feedback or suggestions, please don't hesitate to contact us."]}],[{"l":"Baselime Concepts","p":["Before we continue, we need to learn some of the core Baselime concepts: Observability as Code, datasets, namespaces, and services. They are crucial to understanding how the platform functions. In this page, you will learn about these concepts and how they can help you effectively use Baselime to monitor and troubleshoot your serverless applications."]},{"l":"Observability as Code","p":["In Baselime, Observability as Code refers to the ability to define and manage your observability configurations using code, rather than using a graphical user interface. This allows you to version control your observability configurations, automate their deployment, and more easily share and collaborate with your team.","To implement Observability as Code in Baselime, you will use the Baselime Observability Reference Language (ORL). ORL is a domain-specific language that is used to define observability configurations in a .baselime folder in your code repository. The .baselime folder contains one or more YAML files that define the various aspects of your observability configurations, such as alerts, dashboards, and integrations.","The .baselime folder must contain an index.yaml file, which represents metadata about your service, including its name, description, and details about the cloud infrastructure of the service. The index.yaml file also lists the observability templates that your service uses, as well as any variables that are used in those templates.","To create and manage your observability configurations using ORL, you can use the Baselime CLI and various commands such as baselime init, baselime push, baselime pull or baselime plan. These commands allow you to manage all aspects of your observability configurations from your termnial or your CI/CD pipelines.","In addition to these commands, you can use the baselime report command to report on the health of your service. The baselime report command generates a report that includes information such as the status of your alerts, the performance of your service, and any issues or errors that have been detected. You can view the report in your terminal, or you can integrate it with tools such as GitHub, Slack, or PagerDuty to receive notifications and alerts about the health of your service. When you use the baselime report command, the generated report is based on the observability configurations that you have defined in your .baselime folder using ORL."]},{"l":"Datasets","p":["In Baselime, a dataset is a structured collection of telemetry data that is collected from your serverless applications. Datasets are used to store and query your observability data, and are organized into namespaces.","Baselime supports three types of datasets: logs, metrics, and traces. You can also create your own custom datasets. In addition to these datasets, Baselime includes a dataset for CloudTrail data, which is collected from your AWS account and used to track changes to your serverless architecture.","Logs are structured or unstructured text data that are generated by your serverless applications and services. Examples of log data include log messages, error messages, and debug information.","Metrics are numerical data that represent the performance and behavior of your serverless applications and services. Examples of metric data specific to serverless architectures include average execution duration of Lambda functions, number of invocations of Lambda functions, and number of requests served by API Gateway.","Traces are data that represent the flow of requests through your serverless applications and services. Traces include information about the individual requests and their dependencies, as well as any errors or issues that occurred during processing.","Baselime automatically blocks certain keys, such as email addresses, passwords, and API keys, from being ingested into your datasets. You can also block additional keys as needed by using the baselime block-key command. For example, you might use this command to block sensitive data such as credit card numbers from being ingested into your datasets.","Baselime provides multiple interfaces for viewing and querying your datasets, including a web console, a CLI, and integrations with other tools such as GitHub, Slack, and Jenkins. You can use these interfaces to explore and analyze your datasets, and to troubleshoot issues in your serverless applications."]},{"l":"Namespaces","p":["In Baselime, a namespace is a logical grouping of data within a dataset. You can use namespaces to slice and dice your observability data in order to better understand the behavior and performance of your serverless applications.","Namespaces are automatically inferred from the ingested data and represent the various components of your serverless architecture, such as Lambda functions, DynamoDB tables, and API Gateway APIs. You can use the Baselime CLI or web console to switch between namespaces and view the data for a specific component of your architecture.","Namespaces are also used to organize and access your observability data. You can use the baselime namespaces list command to view a list of all the namespaces ingested in your account."]},{"l":"Services","p":["In Baselime, a service is a logical grouping of cloud resources (such as Lambda functions, databases, and event buses) that represents a specific component of your serverless architecture. It typically corresponds to a repository in your version control system, or a folder in your mono-repo if you use one. Each service is used to organize the telemetry data around the mental model of how your overall application works.","For example, you might have a service called order-management with multiple Lambda functions, databases, and event queues. In Baselime you can run queries within the service, and query only the data emitted by one of the cloud resources that is part of the service, without the clutter of the rest of your architecture. This enables you to isolate, manage and query the observability for each component of your architecture separately.","Services in Baselime are defined by the CloudFormation stacks you create when setting up the service, either through the Baselime Console or using the baselime init command. To view a list of all the available services in your account, use the baselime services list command."]}],[{"l":"Sending Data to Baselime","p":["Baselime ingests your telemetry data and allows you to observe your production environments.","You can send your telemetry data to Baselime with either of: Automatic CloudWatch logs Events API Automatic CloudTrail events Auto-instrumentation with OpenTelemetry (Coming Soon)"]},{"l":"Validation","p":["Events sent to Baselime should not exceed 32kb in raw, uncompressed size per event. Events exceeding this limit will not be ingested and will be dropped."]},{"l":"Semi-structured logs","p":["It is recommended to send events to Baselime in structure JSON format. However, we understand that not every team has made their way through OpenTelemetry or structure logging yet. As such, we support semi-structured logs, such that you and your team can run complex queries on data that hasn't been formatted as per current industry standards.","Baselime automatically detects log events that contain JSON data, but is prepended or appended by a generic string.","The generic string will be wrapped in a message attribute, and the JSON data will be wrapped in a data attribute."]},{"l":"Examples","p":["Here are examples of automatic semi-structured logs detection."]}],[{"l":"CloudWatch Logs","p":["Once you connect your AWS account to Baselime, Baselime automatically create CloudWatch Logs subscription filters to automatically ingest logs from your Lambda functions."]},{"l":"Discovered Keys","p":["Baselime automatically discovers key - value pairs from your AWS Lambdo logs. This empowers you to run complex queries and setup alerts on data that otherwise would be difficult to work with from the AWS Lambda service. For instance, from the discovered keys from the Lambda logs, it's possible to set alerts on the maximum memory used by lambda functions during execution, compared to the amount of memory they are assigned at deployment time."]},{"l":"Lambda Discovered Keys","p":["The Lambda service automatically write logs at the beginning and end of every Lambda function invocation. There logs are parsed as events in Baselime, and keys are automatically discovered from those messages."]},{"l":"START Log Message","p":["The following keys are discovered from the START message:","@type: is always START","@requestId: the request ID of the Lambda invocation","@version: the invoked version of the Lambda function"]},{"l":"END Log Message","p":["The following keys are discovered from the END message:","@type: is always END","@requestId: the request ID of the Lambda invocation"]},{"l":"REPORT Log Message","p":["The following keys are discovered from the REPORT message:","@type: is always REPORT","@requestId: the request ID of the Lambda invocation","@duration: the duration in milliseconds","@billedDuration: the billed duration in milliseconds","@memorySize: the total memory available to the invocation, in MB","@maxMemoryUsed: the max memory used, in MB","@initDuration: the duration of the lambda initialisation in milliseconds (cold starts)","If the Lambda function is instrumented with XRAY, additional keys are discovered:","@xRAYTraceId: the XRAY trace ID","@segmentId: the XRAY segment ID","@sampled: always true"]},{"l":"Timeout Invocations","p":["If your async Lambda invocation times out, Additional keys are automatically discovered:","@timedOut: always true","@timeout: the duration after which the invocation timed-out in seconds","@message: always Task timed out after {@timeout} seconds","@timestamp: the timestamp at the moment the invocation timed out."]},{"i":"consolelog-log-message","l":"console.log Log Message","p":["We recommend writing directly to stdout and stderr from your Lambda functions. For Node.js environments, AWS Lambda uses a modified version of console.log(and other console logging functions) to write to stdout and stderr. These add fields to the log message which are parsed in discovered keys.","@timestamp: the timestamp at the moment the log message was written","@requestId: the request ID of the Lambda invocation","LogLevel: the log level ( INFO, DEBUG, WARN, ERROR)","@message: the message.","If the message in @message is a valid JSON object, Baselime will parse it, otherwise it will be considered a string."]}],[{"l":"Events API","p":["Baselime can ingest your events through our Events API. All requests should be made via HTTPS to events.baselime.io."]},{"l":"Request Format","p":["Each request ingests a batch of events into Baselime. Events are part of the request body. Baselime supports Content-Type application/json.","Requests must be made to the /dataset/namespace route:","dataset is an existing dataset","namespace is created automatically for you when events are received, if it didn't exist beforehand","The request body must be an array of JSON objects. Any element of the array that cannot be parsed as valid JSON will be rejected."]},{"l":"Authentication","p":["The HTTP API requires a valid Baselime API key to be sent in the x-api-key request header.","You can get your API Key using the Baselime CLI."]},{"l":"Validation","p":["The HTTP API validates the provided events and returns a 400 Bad Request status code if any of the events fail validation with a list of all the events that failed validation. If some events pass validation and others fail, we will ingest the events that pass validation. If you encounter a 400 Bad Request error when submitting events to the HTTP API, the events that failed validation will be listed in the body of the request under the invalid key."]},{"l":"High-level requirements","p":["Baselime accepts up to 6MB of uncompressed data per request","Each event must be a properly formatted JSON","Each event must be smaller than 32kb of uncompressed JSON"]},{"l":"Data types","p":["Baselime supports basic data types for the value of each key or nested key of any event:","string","boolean","number"]},{"l":"API Response codes","p":["Baselime returns a 202 response for all valid requests to the HTTP Events API, and a range on of non- 200 responses for errors.","We welcome feeback on API responses and error messages. Reach out to us in our Slack community with any request or suggestion you may have."]},{"l":"Successfull responses","p":["Status Code","Body","Meaning","202","{message: Request Accepted}","All the events were successfully queued for ingestion"]},{"l":"Failure responses","p":["Status Code","Body","Meaning","405","{message: Method Not Allowed}","The HTTP method is now allowed","401","{message: Unauthorised}","Missing or invalid API Key","400","{message: Bad Request}","- Missing or invalid path parameters ( v1, dataset or namespace) - Unable to parse the request body as valid JSON- Empty request body - At least one of the events exceed the 32kb size limit - At least one of the events could not be parsed as valid JSON","500","{message: Internal Error}","An unexpected error occured"]}],[{"l":"CloudTrail Events","p":["Once you connect your AWS account to Baselime, Baselime automatically ingests CloudTrail Events from your AWS environment.","CloudTrail is a managed AWS service which records user activity and API usage across other AWS services. It is useful to debug incidents when the source of the issue is not necessarily application code, but how services communicate with each other. This is particularly relevant for serverless and event-driven applications where significant functionality is taken by cloud infrastructure instead of application code."]},{"l":"CloudTrail management events","p":["CloudTrail events fall into multiple categories, and Baselime automatically ingests CloudTrail management events. Please refer to the complete CloudTrail docs for further details on the CloudTrail concepts."]}],[{"i":"opentelemetry-instrumentation-coming-soon","l":"OpenTelemetry Instrumentation [Coming Soon]","p":["Baselime supports OpenTelemetry to instrument your Lambda functions. [Coming Soon]"]},{"i":"opentelemetry-auto-instrumentation-coming-soon","l":"OpenTelemetry Auto-Instrumentation [Coming Soon]","p":["With OpenTelemetry you can add auto-instrumentation to your Lambda functions. This will collect basic instrumentation to incoming and outgoing requests to your Lambda, as well as Lambda invocations data.","Moreover, Baselime will be able to collect traces across your Lambda invocations.","To auto-instrument your Node.js Lambda function, you need to install the following packages:","Next you need to initialise OpenTelemetry in your Lambda function. Create a tracing.js file that will be executed as the first step of your Lambda invocation.","Deploy your Lambda function using your favourite IaC solution, or in the AWS Console.","In order to instrument the Lambda function, the tracing.js file should be executed before any other file is required in the Lambda handler.","As such, make sure to add the following environment variable to your Lambda:","Alternatively, it should be the first file required at the top of your handler file."]}],[{"i":"observability-reference-language-orl","l":"Observability Reference Language (ORL)","p":["This is the documentation for Baselime's Observability as Code configurations using the Observability Reference Language (ORL).","ORL (Observability Reference Language) is a language used to express queries for observability telemetry data. ORL queries can be used to extract insights from logs, metrics, and traces data sources. ORL queries are defined by a set of parameters that specify the data sources, filters, and calculations to be performed on the data. The result of an ORL query is a set of events that match the criteria defined in the query, optionally aggregated by calculations.","ORL configurations are defined in YAML files.","Generally, ORL files live in the .baselime folder in the root directory of a given project. We refer to this folder as .baselime elsewhere in the documentation, although users can rename it at will.","Multiple integrations and connectors with your favourite Infrastructure as Code platforms are currently being developed."]}],[{"l":"ORL Services","p":["ORL (Observability Reference Language) services are used to organize and manage observability resources such as queries, alerts, and dashboards.","Note that the service must be defined in the madatory index.yml file in the .baselime folder."]},{"l":"Properties","p":["Services have a set of properties that define the service's characteristics and behavior."]},{"i":"version-required","l":"version (required)","p":["The version property is a string that specifies the version of the Baselime CLI used to generate or deploy the service. It is used for version control and management.","Example:"]},{"i":"service-required","l":"service (required)","p":["The service property is a string that specifies the name of the service. It is used to identify the service and distinguish it from other services.","Example:"]},{"i":"description-required","l":"description (required)","p":["The description property is a string that provides more information about the service. It can include details about the purpose of the service, the components it includes, and any other relevant information.","Example:"]},{"i":"provider-required","l":"provider (required)","p":["The provider property is a string that specifies the cloud provider for the service. It is used to identify the provider and distinguish it from other providers. ORL supports the following providers:","aws","gcp(coming soon)","azure(coming soon)","cloudflare(coming soon)","vercel(coming soon)","Example:"]},{"i":"infrastructure-optional","l":"infrastructure (optional)","p":["The infrastructure property is an object that specifies the cloud infrastructure for the service. It has the following properties:"]},{"i":"stacks-optional","l":"stacks (optional)","p":["The stacks property is an array of strings that specifies the CloudFormation stacks that are part of the service. Baselime will automatically find all the cloud resources in the specified stacks and limit all observability rules (queries, alerts, etc.) to these stacks. If the stacks property is not specified, Baselime will include all cloud resources in the environment.","Example:"]},{"i":"templates-optional","l":"templates (optional)","p":["The templates property is an array of strings that specifies the templates to automatically download and implement for the service. Templates are used to define observability rules that can be shared and reused across multiple services. Each string is in the format workspace/template, where workspace is the name of the workspace where the template was defined and template is the unique ID of the template.","Example:"]},{"l":"variables","p":["The variables property is an object that enables you to define variables that can be used in the ORL queries and alerts within the service. These variables can be used to parameterize the ORL queries and alerts and make them more flexible and reusable.","Each variable has a name and one or more values. The values can be grouped by environment (e.g. prod, dev, etc.) or by any other criteria that makes sense for your service.","For example, you might define a threshold variable that has different values for different environments:","In this example, the threshold variable has a default value of 30, and different values for the prod and dev environments: 10 and 20, respectively.","To use this variable in an ORL query or alert, you can use the syntax:","In this example, the threshold variable will be replaced with the appropriate value depending on the environment in which the service is deployed.","It is important to note that variables are optional in services. If a variable is defined, it must have at least one value."]},{"l":"Example ORL Services","p":["Here are example ORL services that combine all of the above properties.","This ORL service is for a web application that is hosted on Amazon Web Services (AWS).","The cloud provider is AWS and the infrastructure consists of two CloudFormation stacks: webapp-stack and database-stack.","The service has two templates defined: baselime/lambda-logs-basics and workspace-name/template-name.","The service has two variables defined: threshold and frequency. The threshold variable has a default value of 30 and a value of 10 for the prod environment. The frequency variable has a default value of 30mins and a value of 5mins for the prod environment and a value of 0 9 ? * 2#1 * for the dev environment.","This ORL service is for a microservices architecture that is hosted on AWS."]}],[{"l":"ORL Queries","p":["ORL (Observability Reference Language) queries are used to retrieve and analyze data from various datasets in order to gain insights and improve observability of systems and services."]},{"l":"properties","p":["ORL queries have a set of properties that define the query's characteristics and behavior."]},{"i":"name-optional","l":"name (optional)","p":["The name of the ORL query is a string used to identify the query. It can be a human-readable name that describes the purpose of the query.","Example:"]},{"i":"description-optional","l":"description (optional)","p":["The description of the ORL query is a string that provides more information about the query. It can include details about the data being queried, the calculations being performed, and any other relevant information.","Example:"]},{"l":"parameters","p":["The parameters of an ORL query define the datasets to query, the calculations to perform on the data, and any filters or groupings to apply."]},{"l":"datasets","p":["The datasets parameter is an array of strings that specify the names of the datasets to query. ORL supports querying multiple datasets simultaneously, allowing you to analyze data from different sources in a single query.","Example:"]},{"i":"filters-optional","l":"filters (optional)","p":["The filters parameter is an array of strings that specify conditions to filter the data by. Each string follows this format: 'key operation value', where key is the field to filter on, operation is the comparison operator to use, and value is the value to compare against. ORL supports the following operations:","=: Equals","!=: Does not equal",": Greater than","=: Greater than or equal to",": Less than","=: Less than or equal to","INCLUDES: Includes (applies to arrays only)","EXISTS: Exists (applies to fields that may or may not exist in the data)","DOES_NOT_EXIST: Does not exist (applies to fields that may or may not exist in the data)","IN: In (applies to arrays only)","NOT_IN: Not in (applies to arrays only)","STARTS_WITH: Starts with (applies to strings only)","Filters can be used to narrow down the data being analyzed and focus on specific events or attributes.","Example:"]},{"i":"calculations-optional","l":"calculations (optional)","p":["The calculations parameter is an array of strings that specify the calculations to perform on the data. ORL supports the following calculations:","COUNT: Counts the number of events","MAX: returns the maximum value of a field across all events.","MIN: returns the minimum value of a field across all events.","SUM: returns the sum of all values of a field across all events.","AVG: returns the average of all values of a field across all events.","MEDIAN: returns the median of all values of a field across all events.","P001, P01, P05, P10, P25, P75, P90, P95, P99, P999: return the specified percentile of all values of a field across all events.","Calculations can be used to perform statistical analysis on the data and derive insights such as the average request duration, the maximum response size, or the 95th percentile of request latencies.","Example:"]},{"i":"groupby-optional","l":"groupBy (optional)","p":["The groupBy parameter is an object that specifies how to segment the data by a field. It has the following fields:","value: The field to group the data by","limit: The maximum number of results to return (default: 10)","type: The type of the data field to group by (string, boolean, or number)","orderBy: The calculation to order the results by (default: the first calculation in the query)","order: The order in which to return the results (ASC or DESC, default: DESC)","Grouping the data by a field allows you to segment the results into distinct groups and analyze them separately.","Example:"]},{"i":"needle-optional","l":"needle (optional)","p":["The needle parameter is an object that specifies a search to perform on the data. It has the following fields:","value: The string to search for","matchCase: A boolean indicating whether the search should be case-sensitive (default: false)","isRegex: A boolean indicating whether the search value is a regular expression (default: false)","The needle can be used to find specific set of events or patterns in the data.","Example:"]},{"l":"Example ORL Queries","p":["Here are example ORL queries that combine all of the above properties.","This ORL query retrieves data from the otel traces dataset and performs several calculations on the data. It computes the average request duration, maximum response size, and 95th percentile of request latencies for each user ID in the dataset.","It filters the data to only include user IDs with a request duration greater than 500ms, and limits the results to the top 100 user IDs based on the average request duration. The results are ordered by the average request duration in descending order. The query also searches for the word \"error\" in the data and filters the results based on whether or not the word is present.","This ORL query calculates the total consumed read capacity units for each DynamoDB table in a service. It filters the data to only include events with a metric_name of ConsumedReadCapacityUnits and a unit of Count, and groups the results by TableName. The query returns the top 10 tables with the highest consumed read capacity units."]}],[{"l":"ORL Alerts","p":["ORL (Observability Reference Language) alerts are used to monitor data from various datasets and trigger notifications when specific conditions are met. ORL alerts are defined by a set of properties that specify the characteristics and behavior of the alert. They are based on ORL queries, which are used to retrieve and analyze the data. This allows you to monitor your systems and services and be notified when there are issues or anomalies that require attention.","Note that an alert can only be set for queries that include calculations. It is not possible to set an alert for a query that does not have any calculations."]},{"l":"properties","p":["ORL alerts have a set of properties that define the alert's characteristics and behavior."]},{"i":"name-optional","l":"name (optional)","p":["The name of the ORL alert is a string used to identify the alert. It can be a human-readable name that describes the purpose of the alert.","Example:"]},{"i":"description-optional","l":"description (optional)","p":["The description of the ORL alert is a string that provides more information about the alert. It can include details about the data being monitored, the conditions or thresholds being checked, and any other relevant information.","Example:"]},{"i":"enabled-optional","l":"enabled (optional)","p":["The enabled property is a boolean that specifies whether the ORL alert is currently active or inactive. If set to true, the alert will be triggered when the conditions or thresholds are met. If set to false, the alert will be disabled and will not trigger."]},{"l":"parameters","p":["The parameters of an ORL alert define the query to use, the frequency at which the query is run, the window of time over which the query's results are analyzed, and the threshold or condition that triggers the alert."]},{"l":"query","p":["The query parameter is a reference to an ORL query that defines the data to be monitored for the alert. It is specified as a string in the format !ref query_name, where query_name is the name of the ORL query.","Example:"]},{"l":"frequency","p":["The frequency parameter is a string that specifies how often the alert is checked. It can follows the format number time_unit, where number is a positive integer and time_unit is one of the following:","mins/ minutes: minutes","h/ hours: hours","d/ days: days","months: months","y/ years: years","The frequency can also be defined as a cron expression, following the AWS Cron Reference","Examples:","15 10 * * ? *: 10:15 AM (UTC) every day 0 18 ? * MON-FRI *: 6:00 PM Monday through Friday 0 8 1 * ? *: 8:00 AM on the first day of the month 0/10 * ? * MON-FRI *: Every 10 min on weekdays 0/5 8-17 ? * MON-FRI *: Every 5 minutes between 8:00 AM and 5:55 PM weekdays 0 9 ? * 2#1 *: 9:00 AM on the first Monday of each month","The alert is checked at the specified interval, and if the conditions are met, the alert is triggered.","Example:"]},{"l":"window","p":["The window parameter is a string that specifies the time window to consider for the alert. It follows the same format as the frequency parameter, but cannot be defined as a CRON expression.","The alert is only triggered if the conditions are met within the specified time window.","Example:"]},{"l":"threshold","p":["The threshold parameter is a string that specifies the threshold at which the alert is triggered. It is be a simple value that inculdes the comparison and the value (e.g. 5).","The threshold is compared to the result of the first calculation in the query of the alert. If the result meets the specified condition, the alert is triggered.","The following comparison operators are supported:","=: Equals","!=: Does not equal",": Greater than","=: Greater than or equal to",": Less than","=: Less than or equal to","Example:"]},{"l":"channels","p":["The channels parameter is an array of objects that specify the channels to send the alert to. ORL supports the following types of channels:","slack: Sends the alert to a Slack channel email: Sends the alert to an email address pagerduty: Triggers a PagerDuty incident webhook: Sends the alert to a custom webhook URL","Each channel type has its own set of properties that define the behavior of the channel."]},{"l":"slack","p":["The slack channel type sends the alert to a Slack channel. It has the following properties:","targets: An array of strings that specify the Slack channels to send the alert to. Each string should be the name of a Slack channel (e.g. general). Example:","Note that it is necessary to install the Baselime Slack app and follow the Slack onboarding to get alerts on Slack."]},{"l":"email","p":["The email channel type sends the alert to an email address. It has the following properties:","targets: An array of strings that specify the email addresses to send the alert to. Each string should be a valid email address.","Example:"]},{"i":"pagerduty-coming-soon","l":"pagerduty [Coming Soon]","p":["The pagerduty channel type triggers a PagerDuty incident. It has the following properties:","serviceKey: A string that specifies the PagerDuty service key to use for the incident. This key is used to identify the PagerDuty service that the incident should be created in. eventAction: A string that specifies the action to take when creating the PagerDuty incident. Valid values are trigger (default) and resolve. client: A string that specifies the name of the client that the incident should be associated with. This is optional and can be used to provide context for the incident. clientUrl: A string that specifies the URL of the client that the incident should be associated with. This is optional and can be used to provide context for the incident.","Example:"]},{"l":"webhook","p":["The webhook channel type sends the alert to a custom webhook URL. It has the following properties:","url: A string that specifies the URL to send the alert to. method: A string that specifies the HTTP method to use when sending the alert. Valid values are POST (default) and GET. headers: An object that specifies the headers to include in the request. body: A string or object that specifies the body of the request. If a string is provided, it will be sent as-is. If an object is provided, it will be serialized as JSON and sent as the request body. (Coming Soon)","Example:"]},{"l":"Example ORL Alerts","p":["Here are example ORL alerts that combine all of the above properties."]},{"l":"DynamoDB ConsumedWriteCapacityUnits Alert","p":["This alert is triggered when the ConsumedWriteCapacityUnits metric for a DynamoDB table exceeds a specified threshold over a specified time window.","The alert is set to run every 15 minutes and check the metric over the past hour.","If the ConsumedWriteCapacityUnits exceed 5 over the past hour, the alert is triggered.","The alert is sent to a Slack channel called #dynamodb-alerts."]},{"l":"Lambda Timeout Alarm","p":["This alert checks the number of invocations that have timed out for Lambda functions in the service, and triggers if the count exceeds 10 over the past 15 minutes. It sends a notification to a custom webhook URL every 5 minutes."]}],[{"l":"Installing the Baselime CLI","p":["The Baselime CLI is the primary way to interact with Baselime and your serverless observability data. It allows you to connect your serverless applications, query and explore your data, and set up integrations with your tools.","You can install the Baselime CLI using one of the following methods:"]},{"l":"Installing"},{"i":"installing-with-homebrew-for-macos","l":"Installing with Homebrew (for MacOS)","p":["Make sure you have Homebrew installed on your system. If you don't, you can install it by following the instructions here.","Run the following commands to add the Baselime tap to your Homebrew installation:"]},{"i":"installing-with-curl-for-macos-and-linux","l":"Installing with curl (for MacOS and Linux)","p":["Run the following command to download and install the Baselime CLI:","MacOS","Linux"]},{"i":"installing-with-npm-for-macos-linux-and-windows","l":"Installing with npm (for MacOS, Linux, and Windows)","p":["Make sure you have npm installed on your system. If you don't, you can install it by following the instructions here.","Run the following command to install the Baselime CLI:"]},{"i":"downloading-the-binary-for-macos-and-linux","l":"Downloading the binary (for MacOS, and Linux)","p":["You can download the latest version of the Baselime CLI binary from the releases page on GitHub.","Download the binary for your operating system and architecture (e.g., baselime_linux_x64 or baselime_darwin_x64).","Unzip the tarball with tar -xf baselime-os-arch-version.tar.gz","Make the binary executable with chmod +x baselime.","Move the binary to a directory in your PATH, such as /usr/local/bin, with mv baselime /usr/local/bin/baselime.","On some systems, you might need to run these commands with sudo."]},{"l":"Verifying the installation","p":["To verify that the Baselime CLI has been installed correctly, run the following command:","You should see the version number of the Baselime CLI that you installed.","If you encounter any issues during the installation process, please don't hesitate to contact us."]},{"l":"Authenticating the CLI","p":["Before you can use the Baselime CLI, you must authenticate it with your Baselime account. To do this, run the following command:","This command opens a new browser window and asks you to sign in to your Baselime account. Once you sign in, the CLI is authenticated and you can start using it to interact with your Baselime account."]},{"l":"Updating the Baselime CLI","p":["To update the Baselime CLI to the latest version, use one of the following commands depending on how you originally installed it:","If you installed with brew, run brew upgrade @baselime/cli","If you installed with curl, run baselime upgrade","If you installed with npm, run npm update -g @baselime/cli"]}],[{"l":"Getting Started with the Baselime CLI","p":["Welcome to the Baselime CLI! This guide will help you get up and running with the CLI so you can start using Baselime to gain visibility into your serverless architecture."]},{"l":"Prerequisites","p":["Before you can use the Baselime CLI, you'll need to:","Install the Baselime CLI. See the installation instructions for more details.","Connect your AWS Account to Baselime. See the quick start guide for instructions on how to do this."]},{"l":"First Steps","p":["Once you have the Baselime CLI installed and your AWS Account connected, you're ready to start using Baselime! Here are a few commands to get you started:","baselime iam: displays information about the current user logged in to the CLI.","baselime services list: List all of the services in the authenticated environment.","baselime query: Run a query against your telemetry data to find specific events or metrics.","baselime tail: Stream all of the events ingested into Baselime in real-time."]},{"l":"Next Steps","p":["Now that you've gotten your feet wet with the Baselime CLI, you can learn more about the other commands and features available. Here are a few places to start:","Check out the CLI reference for a full list of available commands and their options.","Learn about Observability as Code and how you can use it to define and manage your observability configurations.","Explore the Baselime Console and learn how to use it to view and analyze your telemetry data.","Set up integrations with tools like GitHub, Slack, and PagerDuty to get notifications and take action on your observability data."]}],[{"l":"Anonymous Telemetry","p":["Baselime collects completely anonymous telemetry data about general CLI usage. Participation in this anonymous program is optional, and you can opt-out if you'd not like to share any information."]},{"i":"how-do-i-opt-out","l":"How do I opt-out?","p":["You can opt out-by running the following command:","You can re-enable telemetry if you'd like to rejoin the program by running."]},{"i":"why-do-we-collect-telemetry-data","l":"Why do we collect telemetry data?","p":["Telemetry data help up to accurately measure the Baselime CLI feature usage, pain points, and customisation across all developers. This data empowers us to build a better product for more developers.","It also allows us to verify if the improvements we make to the Baselime CLI are having a positive impact on the developer experience."]},{"i":"what-is-being-collected","l":"What is being collected?","p":["We measure the following anonymously:","Command invoked (ie. baselime apply, baselime queries run, or baselime events stream)","Version of Baselime in use","General machine information (e.g. number of CPUs, macOS/Windows/Linux, whether or not the command was run within CI)","An example telemetry event looks like:","These events are then sent to an endpoint hosted on our side."]},{"i":"what-about-sensitive-data-or-secrets","l":"What about sensitive data or secrets?","p":["We do not collect any metrics which may contain sensitive data.","This includes, but is not limited to: environment variables, file paths, contents of files, logs, or serialized errors."]},{"i":"will-the-telemetry-data-be-shared","l":"Will the telemetry data be shared?","p":["The data we collect is completely anonymous, not traceable to the source, and only meaningful in aggregate form.","No data we collect is personally identifiable.","In the future, we plan to share relevant data with the community through public dashboards or reports."]}],[{"l":"baselime alerts","p":["Use the baselime alerts to manage the alerts in your Baselime environment."]}],[{"l":"baselime destroy","p":["Use the baselime destroy to services previously created through Observability as Code."]}],[{"l":"baselime environments","p":["Use the baselime environments command to manage the connection of your AWS accounts to Baselime."]}],[{"l":"baselime iam","p":["Use the baselime iam command to display the currently logged-in user and environment."]}],[{"l":"baselime init","p":["Use the baselime init command to initialize a new service in the current directory."]}],[{"l":"baselime login","p":["Use the baselime login command to log in your Baselime account and select an environment."]}],[{"l":"baselime logout","p":["Use the baselime logout command to log out of Baselime."]}],[{"l":"baselime namespaces","p":["Use the baselime namespaces command to manage namespaces for organizing data within datasets."]}],[{"l":"baselime pull","p":["Use the baselime pull command to update local observability as code configurations with the latest state from the remote systems."]}],[{"l":"baselime push","p":["Use the baselime push command to sync Observability as Code configurations from your local folder to your Baselime account."]}],[{"l":"baselime queries","p":["Use the baselime queries command to manage saved queries."]}],[{"l":"baselime query","p":["Use the baselime query command to run a query on your telemetry data data."]}],[{"l":"baselime report","p":["Use the baselime report command to generate a report based on your observability data and assess the health and performance of your service."]}],[{"l":"baselime services","p":["Use the baselime services command to manage Baselime services."]}],[{"l":"baselime snapshot","p":["Use the baselime snapshot command to check all the alerts in your current service, create snapshots of the results, display them in the terminal, and output them to a file."]}],[{"l":"baselime tail","p":["Use the baselime tail command to stream events from your telemetry data in real-time."]}],[{"l":"baselime telemetry","p":["Use the baselime telemetry command to manage the usage telemetry data collected by the Baselime CLI."]}],[{"l":"baselime templates","p":["Use the baselime telemetry command to manage your observability templates."]}],[{"l":"baselime upgrade","p":["Use the baselime upgrade command to upgrade the Baselime CLI to the latest version. This method will work only if you installed the Baselime CLI with curl -s https://get.baselime.io | bash."]}],[{"l":"baselime validate","p":["Use the baselime validate command to validate your ORL configuration files."]}],[{"l":"Webhook Integration","p":["The Webhook integration enables you and your team to send POST requests to an http endpoint when an alert is triggered.","To set this up, set [channel].properties.type to webhook and a valid URL in the targets array.","When an alert triggers to a webhook channel, HTTP requests are made to the channel targets using the /POST method. Each request carries an event similar to the example outlines below."]}],[{"i":"baselime--slack-integration","l":"Baselime + Slack Integration","p":["The Baselime integration for Slack gives you and your team full visibility into your applications right in Slack channels, where you can get alerted, investigate incidents, and manage your observability, as a team."]}],[{"l":"Authentication","p":["Install the Baselime integraton for Slack.","Once you install the app in your Slack workspace, you can start interacting with Baselime app as a Personal app or access from channels. By default, the Baselime app is enabled in all the public channels. For private channels, you need to explicitly invite /invite @baselime","At this point, your Slack and Baselime user accounts are not linked. You will be prompted to log in Baselime. This is a primary step required to access the app.","Slack welcome message","The primary button will redirect you to the Baselime console where you can login and connect your Slack.","Once this is completed, you will be greeted with a help message \uD83C\uDF89.","Successful login"]}],[{"l":"Automated Alerts","p":["You can set one or multiple Slack channels to receive automated alerts.","Please make sure that the channels defined either are public, or you have manually added the Baselime Slack app to those.","Once configured, When an alert that is configured to send notifications to Slack is triggered, the Baselime Slack app will notify all the configured channels.","Slack alert"]}],[{"l":"Commands","p":["You can use the /baselime command to intercat with Baselime straight from Slack."]},{"l":"queries"},{"l":"run","p":["Run a query.","Options","--application: Name of the application","--ref: Query reference","--from: UTC start time - may also be relative eg: 1h, 20mins","--to: UTC end time - may also be relative eg: 1h, 20mins, now","--id: Query id","Result","Slack queries run result"]},{"l":"list","p":["[Coming Soon]"]},{"l":"help","p":["Displays help."]}],[{"l":"Data Security in Baselime","p":["Baselime is committed to ensuring the security and privacy of our users' data. We have implemented a number of measures to ensure that data is encrypted in transit and at rest, and that it is not accessible from the public internet. Here are some of the key data security features of Baselime:"]},{"l":"Data Encryption","p":["All data transferred to and from Baselime is encrypted in transit using industry-standard protocols such as HTTPS and TLS. In addition, all data is encrypted at rest."]},{"l":"Private VPCs and IAM Roles","p":["Baselime runs in private Virtual Private Clouds (VPCs) and utilizes IAM roles to ensure that data is only accessed by authorized users and processes."]},{"l":"No Public Access","p":["Baselime does not expose any data to the public internet. All data is accessed via secure, authenticated channels."]},{"l":"Modern Best Practices","p":["Baselime follows modern best practices for data security, including regularly updating and patching our systems, implementing network segmentation and access controls, and conducting regular security audits and penetration testing."]},{"l":"Data Scrubbing and Obfuscation","p":["Baselime provides tools for scrubbing and obfuscating sensitive data, such as passwords, secrets, and API keys. Users can block or obfuscate specific keys by dataset using the .baselimeignore file, or by using the baselime scrubbing command. In addition, Baselime automatically scrubs a predefined list of sensitive fields, including \"password\" and \"secret\".","To learn more about how to use these features to protect your data, see the Baselime Telemetry Data Privacy documentation."]},{"l":"Compliance","p":["We're currently working towards compliance with a number of industry-standard security and privacy frameworks, including GDPR, SOC2 and HIPAA. Please contact us for more information on our compliance status."]},{"l":"Support","p":["If you have any questions or concerns about the security of your data in Baselime, please don't hesitate to contact our support team. We are always here to help!"]}],[{"i":"telemetry-data-privacy-in-baselime-coming-soon","l":"Telemetry Data Privacy in Baselime [Coming Soon]","p":["Baselime is designed to help you observe the health and performance of your applications, and part of that involves collecting telemetry data. To ensure the privacy of your data, Baselime provides a number of features that enable you to control which data is collected and how it is used."]},{"l":"Blocking Keys","p":["Baselime enables you to block certain keys from being ingested into your datasets. This is particularly useful for sensitive information such as passwords, API keys, and other personal data. You can block keys for a specific dataset by using the baselime block-key command:","You can also block keys for multiple datasets at once by specifying the --dataset flag multiple times:","In addition to the command-line interface, you can also use a .baselimeignore file to block keys. The .baselimeignore file should be located in the root of your repository and should contain a list of keys to block, one per line, with the associated dataset. For example:"]},{"l":"Obfuscating Keys","p":["In addition to blocking keys, Baselime also allows you to obfuscate keys by replacing their values with a hash. This is useful for cases where you want to keep the structure of your data, but don't want to reveal sensitive information. You can obfuscate keys using the baselime obfuscate-key command:","As with blocking keys, you can obfuscate keys for multiple datasets by specifying the --dataset flag multiple times:","You can also use the .baselimeignore file to obfuscate keys. Just add the obfuscate keyword after the dataset name:","Keep in mind that obfuscating keys is a one-way process, meaning that once a key has been obfuscated, there is no way to recover the original value. Make sure to carefully consider which keys you want to obfuscate."]},{"i":"baselimeignore","l":".baselimeignore","p":["The .baselimeignore file allows you to specify keys that should be either blocked or obfuscated when data is ingested into Baselime. You can use this file to block or obfuscate multiple keys across multiple datasets.","To block or obfuscate a key, add a line to the .baselimeignore file in the following format:","For example, to block the data.user.email key in the logs dataset, you would add the following line to your .baselimeignore file:","To obfuscate the data.user.password key in the metrics dataset, you would add the following line:","Note that the .baselimeignore file should be placed in the root folder of your service and will be applied when you run baselime push.","Keep in mind that the .baselimeignore file is only applied to data that is ingested after the .baselimeignore file is pushed. Data that was ingested before the .baselimeignore file was pushed will not be affected."]},{"l":"Automatic scrubbing","p":["Baselime that automatically blocks sensitive information from being ingested into the telemetry data by default. This is done to ensure that sensitive data is not accidentally exposed.","The following keys are automatically scrubbed:","password","secret","passwd","api_key","pwd","apikey","access_token","auth","credentials","creds","Any nested field in your telemetry data that contains any of these automatically scrubbed keys will be blocked from ingestion by default.","To turn automatic scrubbing on or off for a specific dataset, use the following commands:"]}],[{"l":"Baselime API","p":["The Baselime CLI allows you to interact with your observability configurations and telemetry data through an HTTP API.","All requests should be sent via HTTPS to go.baselime.io with an API key in the Authorization header.","All request payloads should be sent as JSON."]},{"l":"Reference","p":["Auth API Queries API Query Run API Alerts API Defects API Materialized Keys API Search API"]}],[{"l":"API Keys","p":["Every programmatic request sent to Baselime must contain an API key. API keys are used to securely communicate with Baselime."]},{"l":"Managing API Keys","p":["API keys can be generated and revoked using the CLI, the API or in the Web Console. Only workspace owners and admins can create or revoke API keys.","API keys work across all namespaces in a workspace. API keys are not linked to users."]},{"l":"Permissions","p":["API keys can have different permissions that govern access to Baselime resources. By default API keys start with no permissions. In other words, API keys can do nothing in Baselime until you grant them the appropriate permissions.","The API key permissions are as follows:","alerts: can create and manage alerts","applications: can create and manage applications","dashboards: can create and manage dashboards","defects: can create and manage defects","environments: can create and manage environments","events: can send events to Baselime","queries: can create, run and manage queries"]}],[{"l":"Auth API","p":["The auth API is used to validate an authentication key and to verify the actions it's allowed to perform on Baselime."]},{"l":"Verify API Key"},{"l":"Request"},{"l":"Sample Response","p":["The expected response is:"]}],[{"l":"Queries API","p":["The queries API is used to create and manage queries."]},{"l":"Create Query"},{"l":"Request","p":["The payload to create a query should follow the specs below. All fields are optional:","namespaces: a list of namespaces to run the query against","keys: a list of objects representing the fields to retrieve, Each key consists of a key(the name of the key to retrieve) and its type.","calculations: a list of calculations to perform on the events. Calculations consist of a key and operator. If the operator is COUNT, a key is not necessary. calculations and keys cannot be used simultaneously.","filters: a list of objects representing the filters to apply to the query. Each filter consists of a key, an operation and a value. The value could be:","a literal value","another key/ type pair; the key can be a materialized key","filter_combination: AND or OR. If the list of filters contains multiple filters, filter_combination defines how they are applied.","AND: find events matching all filters","OR: find events matching any filter","group_bys: a list of key/ type pairs to group your result by.","orders: a list of objects describing how to order the query results. Each item should include a key, a type and a order which takes either ASCENDING or DESCENDING","name: the name of the query","description: a description of the query","Sample request:"]},{"l":"Sample Response"},{"l":"Get Query"},{"i":"request-1","l":"Request","p":["To retrieve a query, send a GET request to /v1/queries/query_id."]},{"i":"sample-response-1","l":"Sample Response"},{"l":"Update Query"},{"i":"request-2","l":"Request","p":["To update a query, send a PUT request to /v1/queries/query_id. The request body should include all fields that you wish to edit on the query. Only included fields will be updated."]},{"i":"sample-response-2","l":"Sample Response"},{"l":"Delete Query"},{"i":"request-3","l":"Request","p":["To delete a query, send a DELETE request to /v1/queries/query_id. If other resources such as alerts use the current query, the delete operation will fail and respond with status code 403."]},{"i":"sample-response-3","l":"Sample Response"},{"l":"List Queries"},{"i":"request-4","l":"Request","p":["To list queries, send a GET request to /v1/queries/."]},{"i":"sample-response-4","l":"Sample Response"}],[{"l":"Query Run API","p":["The query run API is used to run queries on Baselime.","Running a query on Baselime is asynchronous. You submit a query run request, and the API responds with a receipt. You can subsequently poll the query run API to retrieve the query run result."]},{"l":"Important Considerations","p":["Query results cannot exceed 6MB in size. Pagination is available for queries that exceed 6MB in size.","Query results cannot take more than 10 seconds to run.","Creating a query run is rate limited at 10 requests per minute per workspace."]},{"l":"Create Query Run"},{"l":"Request","p":["The payload to create a query run should follow the specs below.","query_id: the id of the query to run","from: the datetime UNIX timestamp (with milliseconds) of the start time of the query run","to: the datetime UNIX timestamp (with milliseconds) of the end time of the query run","limit[optional]: the maximum number of query results","offset[optional]: the number of query results to skip","Sample request:"]},{"l":"Sample Response"},{"l":"Get Query Run"},{"i":"request-1","l":"Request","p":["To retrieve a query run, send a GET request to /v1/query_run/query_run_id."]},{"i":"sample-response-1","l":"Sample Response"}],[{"l":"Alerts API","p":["The alerts API is used to create and manage alerts."]},{"l":"Create Alert"},{"l":"Request","p":["The payload to create an alert should follow the specs below.","query_id: the ID of the query to use to for the alert. The query must contain exactly one calculation.","threshold: an object describing the threshold to compare with the calculation defined in the query. it consists of an operation and a value.","frequency: the interval in seconds, between consecutive checks of the query calculation.","destinations: a list describing the sinks to the receive the alert when triggered. Each sink is an object with a type and a target.","name: the name of the alert","description: a description of the alert","Sample request:"]},{"l":"Sample Response"},{"l":"Get Alert"},{"i":"request-1","l":"Request","p":["To retrieve an alert, send a GET request to /v1/alerts/alert_id."]},{"i":"sample-response-1","l":"Sample Response"},{"l":"Update Alert"},{"i":"request-2","l":"Request","p":["To update an alert, send a PUT request to /v1/alerts/alert_id. The request body should include all fields that you wish to edit on the alert. Only included fields will be updated."]},{"i":"sample-response-2","l":"Sample Response"},{"l":"Delete Alert"},{"i":"request-3","l":"Request","p":["To delete an alert, send a DELETE request to /v1/alerts/alert_id."]},{"i":"sample-response-3","l":"Sample Response"},{"l":"List Alerts"},{"i":"request-4","l":"Request","p":["To list alerts, send a GET request to /v1/alerts/."]},{"i":"sample-response-4","l":"Sample Response"}],[{"l":"Defects API","p":["The defects API is used to create and manage defects."]},{"l":"Create Defect"},{"l":"Request","p":["The payload to create a defect should follow the specs below.","target: an object describing the entity to flag as a defect. Each target should contain:","type: the type of the target, EVENT for a single event and TRACE for a entire trace.","id: the id of the target.","priority: the priority of the defect, LOW, MEDIUM, HIGH, URGENT.","severity: the severity of the defect, MINOR, MAJOR, CRITICAL, FATAL.","name: the name of the alert","description: a description of the alert","Creating a defect via the API will trigger downstream events, such as notifications to relevant team-members and creating tickets in linked project management software.","Sample request:"]},{"l":"Sample Response"},{"l":"Get Defect"},{"i":"request-1","l":"Request","p":["To retrieve a defect, send a GET request to /v1/defects/defect_id."]},{"i":"sample-response-1","l":"Sample Response"},{"l":"Update Defect"},{"i":"request-2","l":"Request","p":["To update an defect, send a PUT request to /v1/defects/defect_id. The request body should include all fields that you wish to edit on the defect. Only included fields will be updated.","It is not possible to update the target of a defect."]},{"i":"sample-response-2","l":"Sample Response"},{"l":"Delete Defect"},{"i":"request-3","l":"Request","p":["To delete an defect, send a DELETE request to /v1/defects/defect_id."]},{"i":"sample-response-3","l":"Sample Response"},{"l":"List Defects"},{"i":"request-4","l":"Request","p":["To list defects, send a GET request to /v1/defects/.","Filter only resolved or active defects with a query parameter to the request: /v1/defects?resolved=true"]},{"i":"sample-response-4","l":"Sample Response"}],[{"l":"Materialized Keys API","p":["The Materialized Keys API is used to create and manage materialized keys."]},{"l":"Create Materialized Key"},{"l":"Request","p":["The payload to create a materialized key should follow the specs below.","alias: a string representing the materialized_key. An alias can only consist of alpha-numerical characters.","expression: the calculation for the materialized_key. Please make sure to follow the specs.","description: a description of the materialized key","Sample request:"]},{"l":"Sample Response"},{"l":"Get Materialized Key"},{"i":"request-1","l":"Request","p":["To retrieve a materialized key, send a GET request to /v1/materialized_key/materialized_key_id."]},{"i":"sample-response-1","l":"Sample Response"},{"l":"Get Materialized Key by Alias"},{"i":"request-2","l":"Request","p":["To retrieve a materialized key, send a GET request to /v1/materialized_key?alias=materialized_alias."]},{"i":"sample-response-2","l":"Sample Response"},{"l":"Update Materialized Key"},{"i":"request-3","l":"Request","p":["To update an materialized key, send a PUT request to /v1/materialized_key/materialized_key_id. The request body should include all fields that you wish to edit on the materialized key. Only included fields will be updated."]},{"i":"sample-response-3","l":"Sample Response"},{"l":"Delete Materialized Keys"},{"i":"request-4","l":"Request","p":["To delete an materialized key, send a DELETE request to /v1/materialized_key_id/materialized_key_id.","It is not possible to delete materialized keys that are being used by other queries"]},{"i":"sample-response-4","l":"Sample Response"},{"l":"List Materialized Key"},{"i":"request-5","l":"Request","p":["To list materialized key, send a GET request to /v1/materialized_key/."]},{"i":"sample-response-5","l":"Sample Response"}],[{"l":"Search API","p":["The search API is used to search through your events on Baselime.","Searching for a terms in your events on Baselime is asynchronous. You submit a search request, and the API responds with a receipt. You can subsequently poll the search API to retrieve the search result."]},{"l":"Important Considerations","p":["Search results cannot exceed 6MB in size. Pagination is available for search requests that exceed 6MB in size.","Search results cannot take more than 10 seconds to run.","Creating a search request is rate limited at 10 requests per minute per workspace."]},{"l":"Create Search"},{"l":"Request","p":["The payload to create a search should follow the specs below.","term: the term to search through the events","namespaces: a list of namespaces to search across. Each namespace must contain a type and a value.","from: the datetime UNIX timestamp (with milliseconds) of the start time of the search","to: the datetime UNIX timestamp (with milliseconds) of the end time of the search","limit[optional]: the maximum number of search results","offset[optional]: the number of search results to skip","Sample request:"]},{"l":"Sample Response"},{"l":"Get Search"},{"i":"request-1","l":"Request","p":["To retrieve a query run, send a GET request to /v1/search/search_id."]},{"i":"sample-response-1","l":"Sample Response"}],[{"l":"Overview","p":["Baselime uses connctors to automatically ingest telemetry data from your cloud environments."]}],[{"l":"Baselime AWS Connector","p":["The Baselime AWS Connector helps your team automatically:","ingest AWS Lambda logs from CloudWatch","ingest AWS CloudTrail logs for your infrastructure","ingest performace metrics from: [Coming soon]","AWS Lamda functions","DynamoDB tables","SQS queues","EventBridge buses","SNS topics","other serverless services"]},{"l":"Setup","p":["The connector is an automated flow based on a CloudFormation template that can be defined using a wizard.","It can be done using the Baselime CLI or throught the web console."]},{"l":"Using the CLI","p":["To connect a cloud account to Baselime using the CLI, run the following command in your terminal","Once you've followed the interactive steps, the CLI will generate a CloudFormation template for you to deploy on your AWS account. Deploy the temple on your AWS account. Once deployed, login in your newly connected environment from the CLI.","The interactive output should list your newly connected environment.","Within minutes you should get telemetry data flowing through with the command"]},{"l":"Using the Web Console","p":["Navigate to the Baselime web console and login.","Follow the steps on the homescreen to connect a new AWS Account. Baselime will generate a CloudFormation template for you to deploy on your AWS account.","Once the template is deployed on AWS, return to the Baselime web console and refresh the page. You should see the newly connected AWS environment in the list of connected environment.","Within minutes telemtry data from your AWS environment should start displaying in the events streams in the Baselime web console."]},{"l":"Troubleshooting","p":["If you encounter any issers or error when connecting your AWS environment, please don't hesitate to contact us, or join our Slack community where we are always available to support."]},{"l":"CloudFormation Template","p":["The CloudFormation template is open-source and available here."]}],[{"i":"materialized-keys-coming-soon","l":"Materialized Keys [Coming Soon]","p":["Materialized keys are the result of calculations on one or multiple existing keys in your events."]},{"l":"Reference","p":["Materialized keys work a lot like Excel functions. A materialized_key consists of:","one or multiple existing key s or materialized_key s prefixed with $. Example: $@duration","a function. Example: MIN to compute the minimum between two values","numbers: Example: 32","Materialized keys can only take existing key s of type number.","Example materialized_key: LESS(PLUS($@duration, $@initDuration), 100). This will return true for every event where the sum of the @duration and @initDuration is less than 100."]},{"l":"List of operators"},{"l":"Comparison operators","p":["LESS: less than","LESSOREQUALS: less than or equal","GREATER: greater than","GREATEROREQUALS: greater than or equal","EQUALS: equal","NOTEQUALS: not equal"]},{"l":"Math operators","p":["MIN: minimum","MAX: maximum","PLUS: sum","MINUS: subtract","MULTIPLY: multiply","DIVIDE: divide","MODULO: modulo"]}],[{"l":"Accepted Operations and Operators","p":["Operations and Operators are key concepts when creating queries on Baselime.","Operations: an operation is used to compare two or more key s and/or value s","Operators: an operator is used to perform a computation on key s or value s"]},{"l":"Operations","p":["The accepted operations are:","=","!=","INCLUDES","[Coming soon]","STARTS_WITH","ENDS_WITH","EMPTY"]},{"l":"Operators","p":["AVG","COUNT","MAX","MEDIAN","MIN","P001","P01","P05","P10","P25","P75","P90","P95","P99","P999","SUM","The accepted operators are:"]}]]